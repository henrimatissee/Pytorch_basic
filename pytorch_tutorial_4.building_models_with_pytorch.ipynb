{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4d0e4da-e6c5-49e3-891d-db746818d1e6",
   "metadata": {},
   "source": [
    "## Building models with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bfb143-dbb9-4f71-8a2d-7ac591c2ccf3",
   "metadata": {},
   "source": [
    "### torch.nn.Module and torch.nn.Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bf33219-2e44-47c3-96ee-39fbab7a53fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model:\n",
      "TinyModel(\n",
      "  (linear1): Linear(in_features=100, out_features=200, bias=True)\n",
      "  (activation): ReLU()\n",
      "  (linear2): Linear(in_features=200, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n",
      "\n",
      "\n",
      "Just one layer:\n",
      "Linear(in_features=200, out_features=10, bias=True)\n",
      "\n",
      "\n",
      "Model params:\n",
      "Parameter containing:\n",
      "tensor([[-0.0075, -0.0604,  0.0342,  ...,  0.0127, -0.0012, -0.0891],\n",
      "        [ 0.0244,  0.0900, -0.0263,  ..., -0.0509, -0.0254,  0.0733],\n",
      "        [-0.0652, -0.0981,  0.0814,  ..., -0.0504,  0.0674,  0.0655],\n",
      "        ...,\n",
      "        [-0.0941,  0.0473,  0.0610,  ...,  0.0470, -0.0247, -0.0188],\n",
      "        [-0.0131, -0.0672,  0.0310,  ...,  0.0930, -0.0663, -0.0901],\n",
      "        [ 0.0673, -0.0709, -0.0210,  ...,  0.0470,  0.0570, -0.0910]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0735,  0.0620, -0.0872,  0.0041, -0.0500,  0.0237, -0.0474, -0.0921,\n",
      "         0.0596, -0.0763, -0.0524, -0.0260,  0.0272, -0.0265, -0.0366, -0.0980,\n",
      "         0.0161, -0.0488,  0.0601,  0.0133,  0.0870,  0.0362,  0.0605,  0.0927,\n",
      "        -0.0280, -0.0401, -0.0890,  0.0342, -0.0083,  0.0597,  0.0860, -0.0300,\n",
      "        -0.0067,  0.0763, -0.0880,  0.0547,  0.0511,  0.0715,  0.0438, -0.0829,\n",
      "        -0.0011,  0.0105, -0.0453, -0.0933, -0.0946, -0.0046, -0.0682,  0.0969,\n",
      "         0.0974, -0.0493,  0.0841,  0.0851, -0.0485,  0.0417, -0.0840, -0.0612,\n",
      "        -0.0635,  0.0819,  0.0285, -0.0561, -0.0187, -0.0217, -0.0230,  0.0780,\n",
      "         0.0473,  0.0134,  0.0719, -0.0901,  0.0379,  0.0957, -0.0923,  0.0316,\n",
      "        -0.0295, -0.0513,  0.0910,  0.0024,  0.0896, -0.0488,  0.0601,  0.0078,\n",
      "         0.0525,  0.0610, -0.0825,  0.0412,  0.0966,  0.0638,  0.0719, -0.0132,\n",
      "        -0.0170,  0.0930, -0.0064, -0.0224,  0.0154, -0.0414,  0.0241, -0.0624,\n",
      "         0.0859,  0.0950,  0.0543,  0.0428,  0.0862, -0.0789,  0.0430, -0.0769,\n",
      "         0.0902, -0.0334, -0.0690,  0.0144, -0.0297,  0.0489, -0.0821, -0.0185,\n",
      "        -0.0844, -0.0049, -0.0483,  0.0841,  0.0643, -0.0422, -0.0683, -0.0600,\n",
      "        -0.0056,  0.0389, -0.0480, -0.0059,  0.0533, -0.0359,  0.0366, -0.0948,\n",
      "         0.0755,  0.0272,  0.0950,  0.0002,  0.0991,  0.0348,  0.0164,  0.0217,\n",
      "         0.0504,  0.0032, -0.0198,  0.0011,  0.0372, -0.0970, -0.0553,  0.0427,\n",
      "        -0.0606, -0.0457, -0.0050, -0.0706, -0.0570,  0.0966,  0.0329, -0.0464,\n",
      "         0.0099,  0.0565,  0.0418, -0.0152, -0.0340, -0.0825, -0.0942, -0.0494,\n",
      "        -0.0620,  0.0593, -0.0071,  0.0890,  0.0336, -0.0470, -0.0368, -0.0599,\n",
      "        -0.0572, -0.0751, -0.0154, -0.0009,  0.0934, -0.0186, -0.0595, -0.0429,\n",
      "         0.0750, -0.0922, -0.0266, -0.0650, -0.0922, -0.0153,  0.0565, -0.0622,\n",
      "         0.0708,  0.0217, -0.0281, -0.0593, -0.0279,  0.0760, -0.0529, -0.0413,\n",
      "        -0.0127, -0.0814, -0.0862,  0.0063, -0.0862, -0.0838,  0.0714,  0.0318],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0061, -0.0078,  0.0647,  ...,  0.0113, -0.0240, -0.0217],\n",
      "        [-0.0413,  0.0557,  0.0470,  ..., -0.0586,  0.0347, -0.0333],\n",
      "        [-0.0124,  0.0030, -0.0703,  ...,  0.0693,  0.0366,  0.0515],\n",
      "        ...,\n",
      "        [ 0.0440,  0.0502,  0.0224,  ...,  0.0545,  0.0159,  0.0491],\n",
      "        [ 0.0278,  0.0367,  0.0329,  ..., -0.0153,  0.0051,  0.0438],\n",
      "        [ 0.0511, -0.0552, -0.0185,  ..., -0.0580,  0.0247, -0.0653]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0245,  0.0333, -0.0578, -0.0021, -0.0532, -0.0066,  0.0334, -0.0588,\n",
      "        -0.0336, -0.0115], requires_grad=True)\n",
      "\n",
      "\n",
      "Layer params:\n",
      "Parameter containing:\n",
      "tensor([[ 0.0061, -0.0078,  0.0647,  ...,  0.0113, -0.0240, -0.0217],\n",
      "        [-0.0413,  0.0557,  0.0470,  ..., -0.0586,  0.0347, -0.0333],\n",
      "        [-0.0124,  0.0030, -0.0703,  ...,  0.0693,  0.0366,  0.0515],\n",
      "        ...,\n",
      "        [ 0.0440,  0.0502,  0.0224,  ...,  0.0545,  0.0159,  0.0491],\n",
      "        [ 0.0278,  0.0367,  0.0329,  ..., -0.0153,  0.0051,  0.0438],\n",
      "        [ 0.0511, -0.0552, -0.0185,  ..., -0.0580,  0.0247, -0.0653]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0245,  0.0333, -0.0578, -0.0021, -0.0532, -0.0066,  0.0334, -0.0588,\n",
      "        -0.0336, -0.0115], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class TinyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(100, 200)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(200, 10)\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "tinymodel = TinyModel()\n",
    "\n",
    "print('The model:')\n",
    "print(tinymodel)\n",
    "\n",
    "print('\\n\\nJust one layer:')\n",
    "print(tinymodel.linear2)\n",
    "\n",
    "print('\\n\\nModel params:')\n",
    "for param in tinymodel.parameters():\n",
    "    print(param)\n",
    "\n",
    "print('\\n\\nLayer params:')\n",
    "for param in tinymodel.linear2.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b270881-77d8-47bf-9d91-f401cc3398ab",
   "metadata": {},
   "source": [
    "### Common Layer Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bf1dcb-b652-4442-b0f0-d1ca0347af11",
   "metadata": {},
   "source": [
    "#### Linear Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a53e5323-ad4d-4dc1-a582-aad7bca33aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "tensor([[0.8026, 0.6262, 0.6537]])\n",
      "\n",
      "\n",
      "Weight and Bias parameters:\n",
      "Parameter containing:\n",
      "tensor([[ 0.4910,  0.0063, -0.5475],\n",
      "        [ 0.4920, -0.1489,  0.1064]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0999, -0.5635], requires_grad=True)\n",
      "\n",
      "\n",
      "Output:\n",
      "tensor([[ 0.1400, -0.1923]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 모델에 m개 입력과 n개 출력이 있는 경우 가중치는 m*n 행렬이 됨\n",
    "\n",
    "lin = torch.nn.Linear(3, 2)\n",
    "x = torch.rand(1, 3)\n",
    "print('Input:')\n",
    "print(x)\n",
    "\n",
    "print('\\n\\nWeight and Bias parameters:')\n",
    "for param in lin.parameters():\n",
    "    print(param)\n",
    "\n",
    "y = lin(x)\n",
    "print('\\n\\nOutput:')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e659e7a8-6b56-4e99-b078-7322a29dc6f9",
   "metadata": {},
   "source": [
    "#### Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1ea28b0-99a1-4c51-9ff6-cae336781f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.functional as F\n",
    "\n",
    "\n",
    "class LeNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 1 input image channel (black & white), 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = torch.nn.Conv2d(1, 6, 5) # 6 * 28 * 28\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, 3) # 16 * 12 * 12\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = torch.nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = torch.nn.Linear(120, 84)\n",
    "        self.fc3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # 6 * 14 * 14\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) # 16 * 6 * 6\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4244ae-a177-4d01-ae47-eb1cb0467b5d",
   "metadata": {},
   "source": [
    "#### Recurrent Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e4c2aef-95a7-4bec-a289-740726117d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = torch.nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dea2b7b-3cd4-4930-ba66-dcdf4f3cc046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "765b954e-ea98-4197-a338-a08470719881",
   "metadata": {},
   "source": [
    "### Other Layers and Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb6e99e-3bb0-49aa-acbf-245ff1a66d49",
   "metadata": {},
   "source": [
    "#### Data Manipulation Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0c8f4a6-bfc7-49c0-ab39-a2e5a382a359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9191, 0.9620, 0.6940, 0.5174, 0.5445, 0.9370],\n",
      "         [0.7855, 0.2736, 0.0172, 0.2840, 0.3287, 0.0739],\n",
      "         [0.4004, 0.8372, 0.6779, 0.2387, 0.1580, 0.5195],\n",
      "         [0.5005, 0.5857, 0.3439, 0.3425, 0.4621, 0.7411],\n",
      "         [0.5540, 0.6065, 0.7924, 0.8993, 0.2313, 0.3722],\n",
      "         [0.0394, 0.5770, 0.3195, 0.1892, 0.2926, 0.8974]]])\n",
      "tensor([[[0.9620, 0.9370],\n",
      "         [0.7924, 0.8993]]])\n"
     ]
    }
   ],
   "source": [
    "# Max pooling\n",
    "my_tensor = torch.rand(1, 6, 6)\n",
    "print(my_tensor)\n",
    "\n",
    "maxpool_layer = torch.nn.MaxPool2d(3)\n",
    "print(maxpool_layer(my_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fb2f4b4-b47b-4504-a9e3-928b2bcc1ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[10.7628,  5.9726,  5.9309, 10.8419],\n",
      "         [13.5741,  8.0906, 13.4338,  7.5920],\n",
      "         [23.7558,  8.5548, 19.1348, 11.2813],\n",
      "         [18.7796, 11.5719, 10.1376,  5.7251]]])\n",
      "tensor(11.5712)\n",
      "tensor([[[ 0.9836, -0.9913, -1.0085,  1.0162],\n",
      "         [ 1.0226, -0.9101,  0.9732, -1.0858],\n",
      "         [ 1.3307, -1.1745,  0.5691, -0.7252],\n",
      "         [ 1.5389,  0.0039, -0.3016, -1.2413]]],\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "tensor(1.4901e-08, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Normalization layers\n",
    "my_tensor = torch.rand(1, 4, 4) * 20 + 5\n",
    "print(my_tensor)\n",
    "\n",
    "print(my_tensor.mean())\n",
    "\n",
    "norm_layer = torch.nn.BatchNorm1d(4)\n",
    "normed_tensor = norm_layer(my_tensor)\n",
    "print(normed_tensor)\n",
    "\n",
    "print(normed_tensor.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed87061f-4773-45aa-937d-5634cd854a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3433, 0.1102, 0.0000, 0.0000],\n",
      "         [0.7279, 0.3468, 0.5635, 1.0741],\n",
      "         [0.0000, 1.2266, 0.0000, 0.0000],\n",
      "         [0.0000, 1.2634, 0.9685, 0.5141]]])\n",
      "tensor([[[0.0000, 0.0000, 0.9550, 0.0000],\n",
      "         [0.0000, 0.3468, 0.0000, 1.0741],\n",
      "         [1.5275, 1.2266, 1.2983, 0.6745],\n",
      "         [0.1613, 0.0000, 0.0000, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "# Dropout layers\n",
    "my_tensor = torch.rand(1, 4, 4)\n",
    "\n",
    "dropout = torch.nn.Dropout(p=0.4) # default value : 0.5\n",
    "print(dropout(my_tensor))\n",
    "print(dropout(my_tensor))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
